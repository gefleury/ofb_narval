{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0db0e1a9-14eb-4dd1-b6f6-70d467905900",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "On importe toutes les librairies nécéssaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "862df5c1-9c91-4ff3-aa2e-f4a031b12023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "#!pip install unidecode\n",
    "from unidecode import unidecode\n",
    "import torch\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc5f12c3-e2f4-4857-82c4-b6edd59c1cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d1ac06b-75ec-4d99-a4ed-c13aea82677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dad4bd03-36d6-403e-a266-4574c7734a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b22543d6-b0d7-47d3-ac6d-d433b6e453de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ae7d61-a0e0-4053-b099-b07d7fe3c7b3",
   "metadata": {},
   "source": [
    "## Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a37958-21cc-4629-9c96-b4256a5c711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s):\n",
    "    \"\"\"removing caractères, /, accents, m3, /n\"\"\"\n",
    "    import string, re\n",
    "    \n",
    "    def no_unit(text):\n",
    "        regex=\"m3\"\n",
    "        return re.sub(regex, \" \", text)\n",
    "    def no_exp(text):\n",
    "        regex=\"m³\"\n",
    "        return re.sub(regex, \" \", text)\n",
    "    def no_punct(text):\n",
    "        regex=\"\\\\.(?!\\d)\"\n",
    "        return re.sub(regex,\" \",text)\n",
    "   \n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "    def no_date(text):\n",
    "        date_extract_pattern = \"[0-9]{1,2}\\\\/[0-9]{1,2}\\\\/[0-9]{4}\"\n",
    "        return re.sub(date_extract_pattern,\"\",text)\n",
    "    def special_char(text):\n",
    "        regex=regex = \"[^\\w\\s,.]\"\n",
    "        return re.sub(regex, \" \", text)\n",
    "   #on retire tout les caractère des réponses \n",
    "    def no_char(text):\n",
    "        regex=r\"([a-zA-Z])\"\n",
    "        return re.sub(regex, \" \", text)\n",
    "    def comma(text):\n",
    "        regex=\",(?!\\d)\"\n",
    "        return re.sub(regex,\" \",text)\n",
    "    def point(text):\n",
    "        return re.sub(\"\\,\",\".\",text)\n",
    "    def indic(text):\n",
    "        regex=\"(P\\d\\d\\d\\\\.\\d\\s*)|(D\\d\\d\\d\\\\.\\d\\s*)|(VP\\\\.\\d\\d\\d)\"\n",
    "        return re.sub(regex,\" \", text)\n",
    "\n",
    "    return white_space_fix(point(no_punct(no_char(unidecode(comma(special_char(indic(no_exp(no_unit(no_date(s)))))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4e17974-ab82-419d-bb96-4ef30cc3b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(s):\n",
    "    \"\"\"removing caractères, /, accents, m3, /n\"\"\"\n",
    "    import string, re\n",
    "    def no_punct(text):\n",
    "        regex=\"\\\\.(?!\\d)\"\n",
    "        return re.sub(regex,\" \",text)\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "    def special_char(text):\n",
    "        regex=regex = \"[^\\w\\s,.]\"\n",
    "        return re.sub(regex, \" \", text)\n",
    "    def comma(text):\n",
    "        regex=\",(?!\\d)\"\n",
    "        return re.sub(regex,\" \",text)\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(no_punct(unidecode(lower(special_char(s)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37efc216-9cf4-490c-9213-a6f95bb91345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_an(s):\n",
    "    \"\"\"removing caractères, /, accents, m3, /n\"\"\"\n",
    "    import string, re\n",
    "    \n",
    "    def no_unit(text):\n",
    "        regex=\"m3\"\n",
    "        return re.sub(regex, \" \", text)\n",
    "    def no_exp(text):\n",
    "        regex=\"m³\"\n",
    "        return re.sub(regex, \" \", text)\n",
    "    def no_punct(text):\n",
    "        regex=\"\\\\.(?!\\d)\"\n",
    "        return re.sub(regex,\" \",text)\n",
    "   \n",
    "    def white_space_fix(text):\n",
    "        return \"\".join(text.split())\n",
    "    def no_date(text):\n",
    "        date_extract_pattern = \"[0-9]{1,2}\\\\/[0-9]{1,2}\\\\/[0-9]{4}\"\n",
    "        return re.sub(date_extract_pattern,\"\",text)\n",
    "    def special_char(text):\n",
    "        regex=regex = \"[^\\w\\s,.]\"\n",
    "        return re.sub(regex, \" \", text)\n",
    "   #on retire tout les caractère des réponses \n",
    "    def no_char(text):\n",
    "        regex=r\"([a-zA-Z])\"\n",
    "        return re.sub(regex, \" \", text)\n",
    "    def comma(text):\n",
    "        regex=\",(?!\\d)\"\n",
    "        return re.sub(regex,\" \",text)\n",
    "    def point(text):\n",
    "        return re.sub(\"\\,\",\".\",text)\n",
    "    def indic(text):\n",
    "        regex=\"(P\\d\\d\\d\\\\.\\d\\s*)|(D\\d\\d\\d\\\\.\\d\\s*)|(VP\\\\.\\d\\d\\d)\"\n",
    "        return re.sub(regex,\" \", text)\n",
    "\n",
    "    return white_space_fix(point(no_punct(no_char(unidecode(comma(special_char(indic(no_exp(no_unit(no_date(s)))))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ef81fb9-909c-47de-8328-6ab3b4d3c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_space_fix(text):\n",
    "        return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d1c7933-9625-4be4-a1ac-ed4ed4c0f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(text):\n",
    "        return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1b7695b-7380-4c5d-8526-d2bde61227e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saut(text):\n",
    "        regex=\"\\n\"\n",
    "        return re.sub(regex,\"\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2fde92d-5641-4b5c-8af8-ea1dda5d8af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(prediction, truth):\n",
    "    pred_tokens =normalize(prediction).split()\n",
    "    truth_tokens = normalize(truth).split()\n",
    "    \n",
    "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
    "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
    "        return int(pred_tokens == truth_tokens)\n",
    "    \n",
    "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
    "    #print(len(common_tokens))\n",
    "    \n",
    "    # if there are no common tokens then f1 = 0\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "    \n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(truth_tokens)\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7339938b-edb9-4e15-8eda-c1f2459a558a",
   "metadata": {},
   "source": [
    "## Charger les modèles\n",
    "On charge le modèle de question réponse d'etalab pour déceler le nom de la ville, l'année et la compétence mentionnée par le rapport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9110c445-e86b-4374-8b03-0df8ee544288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e84b90d1b244d10b430f2cf4731e320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/515 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12f1e3ed60446c584836f9ffbdaf10c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26620ef1120454d8d10cf164b8c50c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35f18b98bbd4ac9b3cf3ae792a92820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09eab846c29b4861a2f0e93b0c953542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/210 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline('question-answering', model='etalab-ia/camembert-base-squadFR-fquad-piaf', tokenizer='etalab-ia/camembert-base-squadFR-fquad-piaf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2bc612-5ab3-4ae9-a098-bedf596c0e19",
   "metadata": {},
   "source": [
    "## Pré-filtres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9601b5ee-bdee-4397-be9f-bca37fef097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Fonction extrait l'intro\n",
    "def extract_intro(pdf_path):\n",
    "    response = requests.get(pdf_path)\n",
    "    with io.BytesIO(response.content) as f:\n",
    "        reader = PdfReader(f)\n",
    "        page = reader.pages\n",
    "        text = []\n",
    "        for i in range(0, 5):\n",
    "            page = reader.pages[i]\n",
    "            output = page.extract_text()\n",
    "            text.append(output)\n",
    "            text1 = ''\n",
    "        for x in text:\n",
    "            text1 += ' ' + x\n",
    "    return text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "da416402-e1c6-47fd-bb0b-15ac7d9a89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefiltres(text1):\n",
    "    global df\n",
    "   \n",
    "    \n",
    "    # année\n",
    "    année = nlp({'question': \"Quelle est l'année d'exercice du rapport ?\", \n",
    "    'context': text1})\n",
    "    an = normalize_an(année['answer'])\n",
    "    #print(an)\n",
    "\n",
    "    # compétence\n",
    "    reau= \"eau potable\"\n",
    "    rass=\"assainissement\"\n",
    "\n",
    "    d=nlp({'question': \"Quels types de services ? \",\n",
    "         'context': text1})\n",
    "    #print(d)\n",
    "    prediction=d[\"answer\"]\n",
    "    prediction=normalize(prediction)\n",
    "    if ((re.findall(reau,prediction)==[])&(re.findall(rass,prediction)==[])):\n",
    "        d=nlp({'question': \"eau potable ou assainissement collectif ? \",\n",
    "         'context': text1})\n",
    "        #print(d)\n",
    "        prediction=d[\"answer\"]\n",
    "        prediction=normalize(prediction)\n",
    "        if ((re.findall(reau,prediction)==[])&(re.findall(rass,prediction)==[])):\n",
    "            d=nlp({'question': \"Quelle est l'entité de gestion ? \",\n",
    "             'context': text1})\n",
    "            #print(d)\n",
    "            prediction=d[\"answer\"]\n",
    "            prediction=normalize(prediction)\n",
    "            if ((re.findall(reau,prediction)==[])&(re.findall(rass,prediction)==[])):\n",
    "                print(\"type de service non retrouvé dans le texte\")\n",
    "    truth=\"\"\"eau potable\"\"\"\n",
    "    prediction=d['answer']\n",
    "    #print(prediction)\n",
    "    f1_ep=compute_f1(prediction,truth)\n",
    "    #print('f1 eau potable:',f1_ep)\n",
    "\n",
    "    truth=\"\"\"assainissement\"\"\"\n",
    "    prediction=normalize(d['answer'])\n",
    "    f1_ac=compute_f1(prediction,truth)\n",
    "    #print('f1 assainissement:',f1_ac)\n",
    "\n",
    "    if ((re.findall(reau,prediction)!=[])&(re.findall(rass,prediction)!=[])):\n",
    "        #print(re.findall(reau,prediction),re.findall(rass,prediction))\n",
    "        \n",
    "        service=\"AC+EP\"\n",
    "    else:\n",
    "        if (f1_ep > f1_ac ):\n",
    "            service=\"EP\"\n",
    "        if (f1_ep < f1_ac):\n",
    "            service=\"AC\"\n",
    "        if(f1_ep==0)&(f1_ac==0):\n",
    "             service=\"Not defined\"\n",
    "    print(service)\n",
    "    \n",
    "  \n",
    "    #ville\n",
    "    d_ville=nlp({'question': \"Quel est le nom de la commune?\",\n",
    "         'context': text1})\n",
    "    ville=d_ville['answer']\n",
    "    ville=normalize(ville)\n",
    "    print(ville)\n",
    "    if (ville not in df_ville[\"Nom_de_la_commune\"].values):\n",
    "        d_ville=nlp({'question': \"Quel est le nom de la ville?\",\n",
    "         'context': text1})\n",
    "        ville=d_ville['answer']\n",
    "        ville=normalize(ville)\n",
    "        print(ville)\n",
    "        if (ville not in df_ville[\"Nom_de_la_commune\"].values):\n",
    "          print(\"Ville not found\")\n",
    "    print(ville)\n",
    "\n",
    "    return(service,an,ville)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584fbfd5-2f51-42fc-8266-236e1157bfb5",
   "metadata": {},
   "source": [
    "## Charger le fichier d'URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "433ee896-8bc6-498c-94c8-aa4380ec3639",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n",
    "BUCKET = \"/mberthe/narval\"\n",
    "FILE_KEY_Q = \"camemBERT/collect_2023.csv\"\n",
    "FILE_PATH_Q = BUCKET + \"/\" + FILE_KEY_Q\n",
    "\n",
    "with fs.open(FILE_PATH_Q,  mode=\"r\") as file_in:\n",
    "    collect_2023=pd.read_csv(file_in, sep= \";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88d7a364-04af-482d-9716-47f59edbfc4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_2023[\"URL\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff613d8-2403-4a28-81da-0f18a4f815d2",
   "metadata": {},
   "source": [
    "## Charger ville"
   ]
  },
  {
   "cell_type": "raw",
   "id": "231101e8-022a-4485-8e1c-d8758f5c67df",
   "metadata": {},
   "source": [
    "On charge la liste des villes de france, pour vérifier si la ville prédite par le modèle existe, et le cas échéant reformuler la question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63c507f3-78ff-4063-b92d-6da1b3f2f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n",
    "BUCKET = \"/mberthe/narval\"\n",
    "FILE_KEY_Q = \"camemBERT/df_ville.csv\"\n",
    "FILE_PATH_Q = BUCKET + \"/\" + FILE_KEY_Q\n",
    "\n",
    "with fs.open(FILE_PATH_Q,  mode=\"r\") as file_in:\n",
    "    df_ville=pd.read_csv(file_in, sep= \";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c9e3851-9b98-42f2-a680-3891c58de935",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_ville.index:\n",
    "    df_ville[\"Nom_de_la_commune\"][i]=lower(df_ville[\"Nom_de_la_commune\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80a1238-5b60-4f1b-8604-bbcab7aefacc",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f81b7935-2405-4be6-a099-49134f837e90",
   "metadata": {},
   "source": [
    "Recherche des liens comprenant le mot \"RPQS\" puis des pdf présents sur le site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d6878a91-9adf-4509-9a5a-2ad1d920c8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from googlesearch import search\n",
    "requête='RPQS'\n",
    "links=[]\n",
    "\n",
    "for url in  search(requête,start=200,pause=2):\n",
    "    print(\"URL: \",url)\n",
    "    try:\n",
    "        read = requests.get(url)\n",
    " \n",
    "# full html content\n",
    "        html_content = read.content\n",
    " \n",
    "# Parse the html content\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "        for link in soup.find_all('a'):\n",
    "            current_link = link.get('href')\n",
    "        #print(current_link)\n",
    "            if current_link!=None:\n",
    "                if current_link.endswith('pdf'):\n",
    "                    print(\"PDF_link\",current_link)\n",
    "                    links.append(current_link)\n",
    "    except Exception:\n",
    "        pass\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bb5d861d-5dcb-434f-bf6c-db172ff142a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import io\n",
    "from PyPDF2 import PdfFileReader"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4c06f69-95c9-443a-8f21-be0ce14c7a46",
   "metadata": {},
   "source": [
    "On applique les fonctions mentionées en amont pour extraire l'Url, la ville, l'année et la compétence du rapport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d15a60b6-79fa-4f7c-b1db-5a99f4213aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(links)):\n",
    "    if links[i] not in collect_2023[\"URL\"].values:\n",
    "        try :\n",
    "            print(i)\n",
    "            text1=extract_intro(links[i])\n",
    "            #print(\"intro extract\")\n",
    "            service,an,ville = prefiltres(text1)\n",
    "            print(\"lien\",i,\"an:\", an,\"ville:\",ville)\n",
    "            dict_temp={\"URL\":links[i],\"ville\":ville,\"annee\":an,\"competence\":service}\n",
    "            df_result=pd.Series(dict_temp)\n",
    "            df_result=df_result.to_frame()\n",
    "            df_result=df_result.transpose()\n",
    "            collect_2023=pd.concat([collect_2023,df_result])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b9b42321-247f-4856-98e9-4a5b4bcc728e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f2f44417-15ca-471e-9703-54ff598a9261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>ville</th>\n",
       "      <th>annee</th>\n",
       "      <th>competence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.seapan.fr//_medias/fichiers/rpqs-e...</td>\n",
       "      <td>benejacq</td>\n",
       "      <td>2020</td>\n",
       "      <td>AC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.seapan.fr//_medias/fichiers/rpqs-a...</td>\n",
       "      <td>coarraze</td>\n",
       "      <td>2021</td>\n",
       "      <td>AC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.seapan.fr//_medias/fichiers/rpqs-s...</td>\n",
       "      <td>benejacq</td>\n",
       "      <td>2020</td>\n",
       "      <td>AC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.seapan.fr//_medias/fichiers/pac-pl...</td>\n",
       "      <td>monplai sir 64800 ben ejacq</td>\n",
       "      <td>2022</td>\n",
       "      <td>AC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.seapan.fr//_medias/fichiers/rpqs-a...</td>\n",
       "      <td>maison de l eau et de l assai nissement,</td>\n",
       "      <td>2020</td>\n",
       "      <td>AC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://perpignanmediterraneemetropole.fr/wp-c...</td>\n",
       "      <td>perpignan</td>\n",
       "      <td>2019</td>\n",
       "      <td>Not defined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://perpignanmediterraneemetropole.fr/wp-c...</td>\n",
       "      <td>peyrestortes</td>\n",
       "      <td>201820192013</td>\n",
       "      <td>Not defined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://perpignanmediterraneemetropole.fr/wp-c...</td>\n",
       "      <td>peyrestortes</td>\n",
       "      <td>20172018</td>\n",
       "      <td>Not defined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://perpignanmediterraneemetropole.fr/wp-c...</td>\n",
       "      <td>perpignan</td>\n",
       "      <td>2008</td>\n",
       "      <td>Not defined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://perpignanmediterraneemetropole.fr/wp-c...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Not defined</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  URL  \\\n",
       "0   https://www.seapan.fr//_medias/fichiers/rpqs-e...   \n",
       "0   https://www.seapan.fr//_medias/fichiers/rpqs-a...   \n",
       "0   https://www.seapan.fr//_medias/fichiers/rpqs-s...   \n",
       "0   https://www.seapan.fr//_medias/fichiers/pac-pl...   \n",
       "0   https://www.seapan.fr//_medias/fichiers/rpqs-a...   \n",
       "..                                                ...   \n",
       "0   https://perpignanmediterraneemetropole.fr/wp-c...   \n",
       "0   https://perpignanmediterraneemetropole.fr/wp-c...   \n",
       "0   https://perpignanmediterraneemetropole.fr/wp-c...   \n",
       "0   https://perpignanmediterraneemetropole.fr/wp-c...   \n",
       "0   https://perpignanmediterraneemetropole.fr/wp-c...   \n",
       "\n",
       "                                       ville         annee   competence  \n",
       "0                                   benejacq          2020           AC  \n",
       "0                                   coarraze          2021           AC  \n",
       "0                                   benejacq          2020           AC  \n",
       "0                monplai sir 64800 ben ejacq          2022           AC  \n",
       "0   maison de l eau et de l assai nissement,          2020           AC  \n",
       "..                                       ...           ...          ...  \n",
       "0                                  perpignan          2019  Not defined  \n",
       "0                               peyrestortes  201820192013  Not defined  \n",
       "0                               peyrestortes      20172018  Not defined  \n",
       "0                                  perpignan          2008  Not defined  \n",
       "0                                                           Not defined  \n",
       "\n",
       "[522 rows x 4 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5c229faf-05a5-4c57-84ac-53edaa75fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_ENDPOINT_URL = \"https://\" + os.environ[\"AWS_S3_ENDPOINT\"]\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': S3_ENDPOINT_URL})\n",
    "BUCKET_OUT = \"mberthe/narval\"\n",
    "FILE_KEY_OUT_S3 = \"camemBERT/collect_2023.csv\"#modif nom csv\n",
    "FILE_PATH_OUT_S3 = BUCKET_OUT + \"/\" + FILE_KEY_OUT_S3\n",
    "\n",
    "with fs.open(FILE_PATH_OUT_S3, 'w') as file_out:\n",
    "    collect_2023.to_csv(file_out,index=False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c00e6c6-d15b-4655-84f3-2615b130dd54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
